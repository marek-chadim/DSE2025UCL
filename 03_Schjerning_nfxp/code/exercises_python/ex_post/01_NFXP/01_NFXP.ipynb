{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "# magics: ensures that any changes to the modules loaded below will be re-loaded automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler\n",
    "\n",
    "# load general packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# load modules related to this exercise\n",
    "from model_zucher import zurcher\n",
    "from Solve_NFXP import solve_NFXP\n",
    "import estimate_NFXP as estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before solving the exercise, you should download line_profiler. Line_profiler is a tool to check the performance of our code. To install line_profiler, you can open anaconda prompt and write \"pip install line-profiler\" (without the \" \" of course). If you want to know more about line_profiler, check the link below:\n",
    "\n",
    "https://github.com/rkern/line_profiler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider the engine replacement model given by:\n",
    "\n",
    "$$\n",
    "V(x,\\varepsilon) = \\max_{d\\in \\{0,1\\}} \\big\\{ u(x,d) + \\varepsilon_d + \\beta\n",
    "\\underbrace{\\int_{X} \\int_{\\Omega} V(x',\\varepsilon') \\pi(x'|x,d) q(\\varepsilon'|x') dx' d\\varepsilon' }_{EV(x,d)} \\big\\}\n",
    "$$\n",
    "\n",
    "Where $ \\varepsilon $ is extreme value Type I distribued and utility is given by:\n",
    "\n",
    "$$\n",
    "u(x,d)=\\left \\{\n",
    "\\begin{array}{ll}\n",
    "    -RC-c(0,\\theta_1) & \\text{if }d=\\text{replace}=1 \\\\\n",
    "    -c(x,\\theta_1) & \\text{if }d=\\text{keep}=0\n",
    "\\end{array} \\right.\n",
    "$$\n",
    "\n",
    "Here\n",
    "\n",
    "- $ RC $ = replacement cost  \n",
    "- $ c(x,\\theta_1) $ = cost of maintenance with preference parameters $ \\theta_1 $  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Look at ReadMe.txt to get an overview of the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Invistigate how the code works, that is ensure you understand:\n",
    "<il type =\"a\">\n",
    "<li> zurcher.init</li>\n",
    "<li> zurcher.setup</li>\n",
    "<li> zurcher.create_grid</li>\n",
    "<li> zucher.state_transition </li>\n",
    "<li> zucher.bellman </li>\n",
    "\n",
    "You can see how they are called below\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Fill in the missing stuff in the function zucher.bellman and run the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model grid:\n",
      " [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "Transition probabilities conditional on not replacing:\n",
      " [[0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.65 0.2  0.1  0.05 0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.65 0.2  0.1  0.05 0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.65 0.2  0.1  0.05 0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.65 0.2  0.1  0.05 0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.65 0.2  0.1  0.05]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.65 0.2  0.15]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.65 0.35]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.  ]]\n",
      "Transition probabilities conditional on replacing:\n",
      " [[0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]]\n",
      "Bellman one run:\n",
      " [0.47407698 0.47254913 0.47102269 0.46949766 0.46797406 0.46645188\n",
      " 0.46493112 0.46341178 0.46189387 0.46037738 0.45886231 0.45734867]\n"
     ]
    }
   ],
   "source": [
    "do_settings = {\n",
    "    'RC': 0.5,\n",
    "    'n': 12,\n",
    "    'p':[0.65,0.2,0.1]   \n",
    "}\n",
    "model = zurcher(**do_settings)\n",
    "\n",
    "print('Model grid:\\n',model.grid)\n",
    "print('Transition probabilities conditional on not replacing:\\n',model.P1)\n",
    "print('Transition probabilities conditional on replacing:\\n',model.P2)\n",
    "ev,pk, dev = model.bellman(np.zeros((model.n)),output=3)\n",
    "print('Bellman one run:\\n',ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newton's Method\n",
    "\n",
    "Next, we need to solve the model. Rust 1987 uses Newtonâ€“Kantorovich (NK) theorem to solve the Bellman equation in the engine replacement model. To understand the NK algorithm, consider using the Newton's method to solve the single-variable equation, $f(x)=0$. The Newton method uses the iterative procedure stated below to solve the equation:\n",
    "\n",
    "$$x_{n+1} = x_{n} - \\frac{f(x_n)}{f'(x_n)}$$\n",
    "\n",
    "### 4. Use the Newton's Method to solve the equation below. Fill in the Newton step. Try to vary the starting value and see if the solution changes.\n",
    "\n",
    "\n",
    "$$f(x) = 3x^2 - \\exp(x)=0$$\n",
    "\n",
    "$$f'(x) = g(x) = 6x-\\exp(x) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root of f(x): 3.73\n",
      "Number of iterations to archieve convergence: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = lambda x: 3*x**2-np.exp(x)\n",
    "g = lambda x: 6*x-np.exp(x)\n",
    "\n",
    "def newton(f, g, x0, tol=10e-5, max_iter=100):\n",
    "    delta = 2000\n",
    "    it=0\n",
    "    while (max_iter>= it and tol<delta):\n",
    "        x1 = x0 - f(x0)/g(x0)\n",
    "        delta = abs(x1-x0)\n",
    "        it += 1\n",
    "        x0 = x1\n",
    "    return x1, it\n",
    "\n",
    "\n",
    "x0,it = newton(f = f, g = g, x0 = 5)\n",
    "\n",
    "x = np.linspace(-2, 4, num=100)\n",
    "fx = f(x)\n",
    "plt.plot(x, fx)\n",
    "plt.axhline(y=0, color='r', linestyle='-')\n",
    "\n",
    "print('Root of f(x):', round(x0,2))\n",
    "print('Number of iterations to archieve convergence:', it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newton-Kantorovich\n",
    "\n",
    "Now consider solving the engine replacement model. To do so, we need to find the expected value function that solves the Bellman equation.\n",
    "\n",
    "$$\n",
    "EV(x,d) =  \\Gamma(EV)(x,d) \\quad\\Leftrightarrow\\quad (I - \\Gamma)(EV)(x,d)=\\mathbb{0}\n",
    "$$\n",
    "\n",
    "Similar to the Newton iteration, the **NK iteration** uses the following equation\n",
    "\n",
    "$$\n",
    "EV_{k+1} = EV_{k} - (I-\\Gamma')^{-1} (I-\\Gamma)(EV_k)\n",
    "$$\n",
    "\n",
    "- The new operator is the difference between the identity operator \\$I\\$ and Bellman operator $ \\Gamma  $  \n",
    "- $ \\mathbb{0} $ is zero function  \n",
    "- $ I-\\Gamma' $ is a FrÃ©chet derivative of the operator $ I-\\Gamma $  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Solve the model. In order to solve the model, you should understand:\n",
    "<li> solve_NFXP.init</li>\n",
    "<li> solve_NFXP.setup</li>\n",
    "<li> solve_NFXP.poly </li>\n",
    "<li> solve_NFXP.sa </li>\n",
    "<li> solve_NFXP.nk </li>\n",
    "</il>\n",
    "You can see how they are called below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin contraction iterations (for the 1 time)\n",
      "Iteration 1, tol     0.4273, tol(j)/tol(j-1)        nan\n",
      "Iteration 2, tol     0.4272, tol(j)/tol(j-1)        nan\n",
      "Iteration 3, tol     0.4272, tol(j)/tol(j-1)        nan\n",
      "Iteration 4, tol     0.4271, tol(j)/tol(j-1)        nan\n",
      "Iteration 5, tol     0.4271, tol(j)/tol(j-1)        nan\n",
      "Iteration 6, tol      0.427, tol(j)/tol(j-1)        nan\n",
      "Iteration 7, tol     0.4269, tol(j)/tol(j-1)        nan\n",
      "Iteration 8, tol     0.4268, tol(j)/tol(j-1)        nan\n",
      "Iteration 9, tol     0.4266, tol(j)/tol(j-1)        nan\n",
      "Iteration 10, tol     0.4264, tol(j)/tol(j-1)        nan\n",
      "Iteration 11, tol     0.4262, tol(j)/tol(j-1)     0.9994\n",
      "SA stopped prematurely due to relative tolerance. Start NK iterations\n",
      "Elapsed time 0.0146 seconds\n",
      "Begin Newton-Kantorovich iterations (for the 1 time)\n",
      "Iteration 1, tol      13.17, tol(j)/tol(j-1)          1\n",
      "Iteration 2, tol      0.308, tol(j)/tol(j-1)    0.02339\n",
      "Iteration 3, tol    0.08956, tol(j)/tol(j-1)     0.2907\n",
      "Iteration 4, tol   0.003309, tol(j)/tol(j-1)    0.03695\n",
      "Iteration 5, tol  1.158e-05, tol(j)/tol(j-1)   0.003499\n",
      "Iteration 6, tol  2.829e-10, tol(j)/tol(j-1)  2.443e-05\n",
      "N-K converged after 6 iterations, tolerance: 2.829e-10\n",
      "Elapsed time 0.0321 seconds\n",
      "Convergence achieved!\n",
      "Elapsed time: 0.0594 (seconds)\n"
     ]
    }
   ],
   "source": [
    "algorithm = 'poly'\n",
    "do_settings_solver = {\n",
    "    'sa_min': 10,\n",
    "    'sa_max': 1000000,  \n",
    "    'printfxp': 2\n",
    "}\n",
    "\n",
    "solver = solve_NFXP(**do_settings_solver)\n",
    "model = zurcher()\n",
    "\n",
    "ev0 = np.zeros((model.n)) # Initial guess\n",
    "if algorithm == 'sa':\n",
    "    ev = solver.sa(model.bellman, ev0)\n",
    "elif algorithm == 'poly':\n",
    "    ev = solver.poly(model.bellman, ev0, beta = model.beta)\n",
    "else:\n",
    "    print('Algorithm must be \"sa\" or \"poly\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Now we have to estimate the model. In order to estimate the model, you should understand:\n",
    "<il type =\"a\">\n",
    "<li> zurcher.read_busdata </li>\n",
    "<li> estimate_NFXP.estimate  </li>\n",
    "<li> estimate_NFXP.ll  </li>\n",
    "</il>\n",
    "\n",
    "You can see how they are called below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Fill in the missing stuff in the function estimate_NFXP.ll, and estimate the model to check that your results are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structual estimation using busdata from Rust(1987)\n",
      "Beta        = 0.9999\n",
      "n           = 175\n",
      "Sample size = 8156\n",
      " \n",
      "\n",
      "Parameters     Estimates    s.e. \n",
      "RC             9.7689     1.2264 \n",
      "c              1.3427     0.3153 \n",
      " \n",
      "p(1)           0.1069     0.0035  \n",
      "p(2)           0.5154     0.0059  \n",
      "p(3)           0.3621     0.0055  \n",
      "p(4)           0.0143     0.0013  \n",
      "\n",
      "Log-likelihood -8599.86\n",
      "runtime (seconds) 1.9350\n",
      "The model converged: True\n"
     ]
    }
   ],
   "source": [
    "# Set up the model\n",
    "model = zurcher()\n",
    "\n",
    "# Set-up solver\n",
    "solver = solve_NFXP()\n",
    "\n",
    "# Read the data\n",
    "data = model.read_busdata(bustypes=[1,2,3,4])\n",
    "samplesize = data.shape[0]\n",
    "\n",
    "# Estimate the model\n",
    "import time\n",
    "t0 = time.time()\n",
    "theta0 = [0,0]\n",
    "\n",
    "# args for nfxp estimate\n",
    "nfxp_model, optim_res, pnames, theta_hat, Avar, converged=estimate.estimate(model, solver,data,theta0=theta0, twostep=0)\n",
    "\n",
    "t1 = time.time()\n",
    "time = t1-t0\n",
    "\n",
    "# Print the result\n",
    "print(f'Structual estimation using busdata from Rust(1987)')\n",
    "print(f'Beta        = {model.beta:.4f}')\n",
    "print(f'n           = {model.n}')\n",
    "print(f'Sample size = {samplesize}\\n \\n')\n",
    "\n",
    "print(f'Parameters     Estimates    s.e. ') \n",
    "print(f'{pnames[0]}             {theta_hat[0]:.4f}     {np.sqrt(Avar[0,0]):.4f} ')\n",
    "print(f'{pnames[1]}              {theta_hat[1]:.4f}     {np.sqrt(Avar[1,1]):.4f} \\n ')\n",
    "print(f'{pnames[2]}(1)           {theta_hat[2]:.4f}     {np.sqrt(Avar[2,2]):.4f}  ')\n",
    "print(f'{pnames[2]}(2)           {theta_hat[3]:.4f}     {np.sqrt(Avar[3,3]):.4f}  ')\n",
    "print(f'{pnames[2]}(3)           {theta_hat[4]:.4f}     {np.sqrt(Avar[4,4]):.4f}  ')\n",
    "print(f'{pnames[2]}(4)           {theta_hat[5]:.4f}     {np.sqrt(Avar[5,5]):.4f}  \\n')\n",
    "\n",
    "\n",
    "print(f'Log-likelihood {-optim_res.fun*samplesize:.2f}') \n",
    "print(f'runtime (seconds) {time:.4f}')\n",
    "print(f'The model converged: {converged}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Try using line_profiler in python. This gives you a lot of information about the performance of your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 1.9165 s\n",
      "File: /Users/marek/github/DSE2025UCL/03_Schjerning_nfxp/code/exercises_python/ex_post/01_NFXP/estimate_NFXP.py\n",
      "Function: estimate at line 9\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     9                                           def estimate(model,solver,data,theta0=[0,0],twostep=0):\n",
      "    10                                               \"\"\"\" Estimate model using NFXP\"\"\"\n",
      "    11                                               global ev\n",
      "    12         1      16000.0  16000.0      0.0      ev = np.zeros((model.n)) \n",
      "    13                                               \n",
      "    14         1      20000.0  20000.0      0.0      samplesize = data.shape[0]\n",
      "    15                                               \n",
      "    16                                               # STEP 1: Find p non-parametrically\n",
      "    17         1    1830000.0 1.83e+06      0.1      tabulate = data.dx1.value_counts() # Count number of observations for each dx1\n",
      "    18         1    1597000.0  1.6e+06      0.1      p = [tabulate[i]/sum(tabulate) if i < len(tabulate) else 0 for i in range(len(model.p))]\n",
      "    19                                           \n",
      "    20                                               # STEP 2: Estimate structual parameters\n",
      "    21         1      11000.0  11000.0      0.0      model.p[:] = p # Use first step estimates as starting values for p\n",
      "    22                                               \n",
      "    23                                               # Estimate RC and C\n",
      "    24         1       1000.0   1000.0      0.0      pnames = ['RC','c']\n",
      "    25                                               \n",
      "    26                                               # Call BHHH optimizer\n",
      "    27         1 1453677000.0 1.45e+09     75.9      res = optimize.minimize(ll,theta0,args = (model, solver, data, pnames), method = 'trust-ncg',jac = grad, hess = hes, tol=1e-8)\n",
      "    28                                               # Update parameters\n",
      "    29         1      20000.0  20000.0      0.0      model = updatepar(model,pnames,res.x)\n",
      "    30                                               \n",
      "    31                                               # Estimate RC, c and p\n",
      "    32         1          0.0      0.0      0.0      if twostep == 0:\n",
      "    33         1       1000.0   1000.0      0.0          pnames = ['RC','c','p']\n",
      "    34         1       4000.0   4000.0      0.0          theta0 = [model.RC, model.c] + model.p.tolist() # Starting values\n",
      "    35                                                   # Call BHHH optimizer\n",
      "    36         1  444333000.0 4.44e+08     23.2          res = optimize.minimize(ll,theta0, args = (model,solver,data, pnames), method = 'trust-ncg',jac = grad, hess = hes, tol = 1e-8)\n",
      "    37                                           \n",
      "    38                                                   # Update parameters\n",
      "    39         1      21000.0  21000.0      0.0          model=updatepar(model,pnames,res.x)\n",
      "    40                                           \n",
      "    41                                               # Converged: \"trust-ncg tends to be very conservative about convergence, and will often return status 2 even when the solution is good.\"\n",
      "    42         1       3000.0   3000.0      0.0      converged   =   (res.status == 2 or res.status ==0)\n",
      "    43                                           \n",
      "    44                                               # Compute Variance-Covaiance matrix\n",
      "    45         1   14924000.0 1.49e+07      0.8      h = hes(res.x, model, solver,data, pnames) # Hessian\n",
      "    46         1      41000.0  41000.0      0.0      Avar = np.linalg.inv(h*samplesize) # Variance-Covariance matrix from information matrix equality\n",
      "    47                                           \n",
      "    48         1       4000.0   4000.0      0.0      theta_hat = res.x # unpack estimates\n",
      "    49                                               \n",
      "    50         1          0.0      0.0      0.0      return model, res, pnames, theta_hat, Avar, converged\n",
      "\n",
      "Total time: 1.81504 s\n",
      "File: /Users/marek/github/DSE2025UCL/03_Schjerning_nfxp/code/exercises_python/ex_post/01_NFXP/estimate_NFXP.py\n",
      "Function: ll at line 52\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    52                                           def ll(theta, model, solver,data, pnames, out=1, no_guess = False): # out=1 solve optimization\n",
      "    53                                               \"\"\" Compute log-likelihood function \"\"\"\n",
      "    54                                               global ev # Use global variable to store value function to use as starting value for next iteration\n",
      "    55                                               \n",
      "    56                                               #Unpack and convert to numpy array\n",
      "    57       110   52138000.0 473981.8      2.9      x = np.array(data.x - 1) # x is the index of the observed state: We subtract 1 because python starts counting at 0\n",
      "    58       110   10557000.0  95972.7      0.6      d = np.array(data.d) # d is the observed decision\n",
      "    59       110   10101000.0  91827.3      0.6      dx1 = np.array(data.dx1) # dx1 is observed change in x \n",
      "    60                                           \n",
      "    61       110      89000.0    809.1      0.0      if no_guess == True: #Set ev to zero instead of using global variable\n",
      "    62                                                   ev = np.zeros((model.n))\n",
      "    63                                               \n",
      "    64                                               # Update values\n",
      "    65       110    1226000.0  11145.5      0.1      model=updatepar(model,pnames,theta)\n",
      "    66       110     348000.0   3163.6      0.0      model.p = np.abs(model.p)    # helps BHHH which is run as unconstrained optimization\n",
      "    67       110   60180000.0 547090.9      3.3      model.create_grid() # Update grid\n",
      "    68       110      77000.0    700.0      0.0      ev0 = ev # Use previous value function as starting value\n",
      "    69                                           \n",
      "    70                                               # Solve the model\n",
      "    71       110 1664125000.0 1.51e+07     91.7      ev, pk, dev = solver.poly(model.bellman, V0=ev0 ,beta=model.beta, output=3)\n",
      "    72                                           \n",
      "    73                                               # Evaluate likelihood function\n",
      "    74       110    1394000.0  12672.7      0.1      lik_pr = pk[x] # Get probability of keeping given observed state    \n",
      "    75       110    3223000.0  29300.0      0.2      choice_prob = lik_pr * (1 - d) + (1-lik_pr) * d # get probability of making observed choice\n",
      "    76       110    5873000.0  53390.9      0.3      log_lik = np.log(choice_prob)  # Compute log-likelihood-contributions\n",
      "    77                                               \n",
      "    78                                               # add on log like for mileage process\n",
      "    79       110     102000.0    927.3      0.0      if theta.size>2: # theta > 2 if there are parameters for p\n",
      "    80        31    1062000.0  34258.1      0.1          p = np.append(model.p,1-np.sum(model.p)) # Add residual probability to p\n",
      "    81        31     159000.0   5129.0      0.0          if any(p<=0):\n",
      "    82         5     106000.0  21200.0      0.0              log_lik -= 100000*p[dx1] # Penalize if p is negative\n",
      "    83                                                   else:\n",
      "    84        26    1612000.0  62000.0      0.1              log_lik += np.log(p[dx1]) # Add log-likelihood contribution\n",
      "    85                                                   \n",
      "    86                                               else:\n",
      "    87        79      63000.0    797.5      0.0          p = np.nan\n",
      "    88                                           \n",
      "    89                                           \n",
      "    90       110      75000.0    681.8      0.0      if out == 1:\n",
      "    91                                                   # Objective function (negative mean log likleihood)\n",
      "    92        55    2484000.0  45163.6      0.1          return np.mean(-log_lik)\n",
      "    93                                           \n",
      "    94        55      47000.0    854.5      0.0      return model,lik_pr, pk, ev, dev, d,x,dx1"
     ]
    }
   ],
   "source": [
    "%lprun -f estimate.ll  -f estimate.estimate estimate.estimate(model, solver,data,theta0=theta0, twostep=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 0.020657 s\n",
      "File: /Users/marek/github/DSE2025UCL/03_Schjerning_nfxp/code/exercises_python/ex_post/01_NFXP/Solve_NFXP.py\n",
      "Function: solve_NFXP.poly at line 31\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    31                                               def poly(self,bellman, V0=np.zeros(1), beta= 0.0, output=1):\n",
      "    32                                                   \"\"\"\" Solves the model using the poly-algorithm.\n",
      "    33                                                   set beta = 0.0 if you want to solve only with successive approximations.\n",
      "    34                                                   \"\"\"\n",
      "    35                                           \n",
      "    36         1       2000.0   2000.0      0.0          t0poly = time.time()  # set the starting time\n",
      "    37                                           \n",
      "    38                                                   # Loop over the maximum number of switches between contraction iterations and Newton-Kantorovich iterations\n",
      "    39         6       8000.0   1333.3      0.0          for k in range(self.max_fxpiter):\n",
      "    40                                           \n",
      "    41                                                       # 1. CONTRACTION ITERATIONS (S-A)\n",
      "    42         5       9000.0   1800.0      0.0              if self.printfxp>0:\n",
      "    43                                                           print(f'Begin contraction iterations (for the {k+1} time)')\n",
      "    44         5    5266000.0 1.05e+06     25.5              V0,iter_sa= self.sa(bellman,V0,beta)\n",
      "    45                                           \n",
      "    46                                                       # 2. NEWTON-KANTOROVICH ITERATIONS\n",
      "    47         5       4000.0    800.0      0.0              if self.printfxp>0:\n",
      "    48                                                           print(f'Begin Newton-Kantorovich iterations (for the {k+1} time)')\n",
      "    49         5   15353000.0 3.07e+06     74.3              V0,pk,dV, iter_nk = self.nk(bellman,V0)\n",
      "    50                                           \n",
      "    51                                           \n",
      "    52         5       7000.0   1400.0      0.0              t1poly = time.time()\n",
      "    53         5       2000.0    400.0      0.0              if iter_nk.converged=='true':\n",
      "    54         5       5000.0   1000.0      0.0                  if self.printfxp>0:\n",
      "    55                                                               print(f'Convergence achieved!')\n",
      "    56                                                               print(f'Elapsed time: {(t1poly-t0poly):.4f} (seconds)')\n",
      "    57                                                               break \n",
      "    58                                                       else:\n",
      "    59                                                           if k >= self.max_fxpiter:\n",
      "    60                                                               print(f'No convergence! Maximum number of iterations exceeded without convergence!')\n",
      "    61                                                               break\n",
      "    62         1       1000.0   1000.0      0.0          V = V0\n",
      "    63         1          0.0      0.0      0.0          if output==1:            \n",
      "    64         1          0.0      0.0      0.0              return V\n",
      "    65                                                   if output==2:            \n",
      "    66                                                       return V, pk\n",
      "    67                                                   if output==3:            \n",
      "    68                                                       return V, pk, dV\n",
      "    69                                                   if output==5:            \n",
      "    70                                                       return V, pk, dV, iter_sa, iter_nk\n",
      "    71                                                   else:\n",
      "    72                                                       print('solve_NFXP.poly: output must be 1,2,3 or 5')\n",
      "\n",
      "Total time: 0.015256 s\n",
      "File: /Users/marek/github/DSE2025UCL/03_Schjerning_nfxp/code/exercises_python/ex_post/01_NFXP/Solve_NFXP.py\n",
      "Function: solve_NFXP.nk at line 117\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   117                                               def nk(self,bellman, V0):\n",
      "   118                                                   \"\"\"\"Solves the model using the Newton-Kantorovich steps\"\"\"\n",
      "   119                                                   #Empty class to store the iteration output\n",
      "   120         5      54000.0  10800.0      0.4          class iteration: pass\n",
      "   121         5      12000.0   2400.0      0.1          t0 = time.time()\n",
      "   122         5      15000.0   3000.0      0.1          iteration.tol =  np.nan+np.zeros((self.pi_max))\n",
      "   123         5       9000.0   1800.0      0.1          iteration.rtol = np.nan+np.zeros((self.pi_max))\n",
      "   124         5       8000.0   1600.0      0.1          iteration.converged = 'false'\n",
      "   125                                                   # Get the state space size\n",
      "   126         5       4000.0    800.0      0.0          m = V0.size\n",
      "   127                                                   # Loop over the maximum number of Newton-Kantorovich steps\n",
      "   128        10      11000.0   1100.0      0.1          for i in range(self.pi_max):\n",
      "   129                                           \n",
      "   130                                                       # NK-step\n",
      "   131        10    1913000.0 191300.0     12.5              V1, pk, dV = bellman(V0,output=3) # Get derivative of bellman operator\n",
      "   132        10     362000.0  36200.0      2.4              F = np.eye(m)-dV # Compute frechet derivative\n",
      "   133        10   11829000.0 1.18e+06     77.5              V = V0 - np.linalg.inv(F) @ (V0 - V1)  # Do N-K step\n",
      "   134                                                       \n",
      "   135                                                       # do additional SA iteration for stability and accurate measure of error bound\n",
      "   136        10     652000.0  65200.0      4.3              V0 = bellman(V,output=1)\n",
      "   137                                           \n",
      "   138                                                       # Tolerance\n",
      "   139        10     148000.0  14800.0      1.0              iteration.tol[i]=max(abs(V-V0))\n",
      "   140        10      15000.0   1500.0      0.1              iteration.rtol[i] = iteration.tol[i]/(iteration.tol[max(i-1,0)] + 1.0e-15)      \n",
      "   141                                           \n",
      "   142                                                       #Adjust \n",
      "   143        10     140000.0  14000.0      0.9              adj  = np.ceil(np.log10(abs(max(V0))))\n",
      "   144        10       9000.0    900.0      0.1              ltol = self.pi_tol*10**adj  # Adjust final tolerance\n",
      "   145                                           \n",
      "   146        10       8000.0    800.0      0.1              if iteration.tol[i] < ltol:\n",
      "   147                                                           #Convergence achieved\n",
      "   148         5      25000.0   5000.0      0.2                  iteration.message = \"N-K converged after {} iterations, tolerance: {:.4g}\".format(i+1,iteration.tol[i])\n",
      "   149         5       5000.0   1000.0      0.0                  iteration.converged = 'true'\n",
      "   150         5       1000.0    200.0      0.0                  break\n",
      "   151                                                   # Store the iteration output\n",
      "   152         5       2000.0    400.0      0.0          iteration.n = i+1\n",
      "   153         5       6000.0   1200.0      0.0          iteration.tol = iteration.tol[0:i+1]\n",
      "   154         5       5000.0   1000.0      0.0          iteration.rtol = iteration.rtol[0:i+1]\n",
      "   155         5       8000.0   1600.0      0.1          t1 = time.time()\n",
      "   156         5       1000.0    200.0      0.0          iteration.time = t1-t0 \n",
      "   157                                           \n",
      "   158         5      10000.0   2000.0      0.1          self.print_output(iteration)\n",
      "   159                                           \n",
      "   160         5       4000.0    800.0      0.0          return V, pk, dV, iteration"
     ]
    }
   ],
   "source": [
    "ev0 = np.zeros((model.n)) # Initial guess\n",
    "%lprun -f solve_NFXP.nk -f solve_NFXP.poly solve_NFXP.poly(solver,model.bellman, ev0, beta = model.beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Now try changing the optimizer options, and turn the use of the non-numerical Hessian off . What happens?\n",
    "\n",
    "b) Now also try it with the analytical gradient off, what happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BHHH:\n",
      "Time is 1.5158 seconds. The model converges: True\n",
      "Time is 1.4528 seconds. The model converges: True\n",
      "Time is 2.2451 seconds. The model converges: True\n",
      "Time is 1.4657 seconds. The model converges: True\n",
      "Time is 1.5519 seconds. The model converges: True\n",
      "Time is 1.4634 seconds. The model converges: True\n",
      "Time is 1.4703 seconds. The model converges: True\n",
      "Time is 1.5318 seconds. The model converges: True\n",
      "1.6 s Â± 267 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Hessian is off:\n",
      "Time is 4.6663 seconds. The model converges: True\n",
      "Time is 4.2466 seconds. The model converges: True\n",
      "Time is 3.0185 seconds. The model converges: True\n",
      "Time is 4.1195 seconds. The model converges: True\n",
      "Time is 4.7531 seconds. The model converges: True\n",
      "Time is 3.7312 seconds. The model converges: True\n",
      "Time is 2.8225 seconds. The model converges: True\n",
      "Time is 2.8357 seconds. The model converges: True\n",
      "3.65 s Â± 712 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "Hessian and gradient are off:\n",
      "Time is 3.7566 seconds. The model converges: True\n",
      "Time is 3.6990 seconds. The model converges: True\n",
      "Time is 3.7669 seconds. The model converges: True\n",
      "Time is 3.7744 seconds. The model converges: True\n",
      "Time is 3.8458 seconds. The model converges: True\n",
      "Time is 3.7468 seconds. The model converges: True\n",
      "Time is 3.7272 seconds. The model converges: True\n",
      "Time is 3.7009 seconds. The model converges: True\n",
      "3.75 s Â± 47.2 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "import alternative_specifications_ex7 as a_s_ex7\n",
    "import warnings\n",
    "# Turn off warnings: We turn of warnings as a result of overflow. This occurs as the optimizer will sometimes guess on non-feasible transition probabilities. \n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "model = zurcher()\n",
    "solver = solve_NFXP()\n",
    "\n",
    "#Ordinaty\n",
    "print('BHHH:')\n",
    "%timeit nfxp_results = a_s_ex7.estimate(model, solver,data,theta0=theta0, twostep=0,est_type=0)\n",
    "\n",
    "\n",
    "# Hessian off\n",
    "print('')\n",
    "print('Hessian is off:')\n",
    "%timeit nfxp_result = a_s_ex7.estimate(model, solver,data, twostep=0,est_type=1)\n",
    "\n",
    "\n",
    "# #Hessian and gradient ofF \n",
    "print('')\n",
    "print('Hessian and gradient are off:')\n",
    "%timeit nfxp_results = a_s_ex7.estimate(model, solver,data,theta0=theta0, twostep=0,est_type=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Try estimate the model for different values of $\\beta$. \n",
    "\n",
    "(a) Why can we not estimate $\\beta$?\n",
    "\n",
    "(b) When estimating with different $\\beta$, do the changes in the estimates of c and/or RC make intuitively sense?\n",
    "\n",
    "(c) Can you think of some data/variation, which could allow us to identify $\\beta$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta     RC     C       log_lik\n",
      "0.5000 7.3664 18.5137 [-8605.91245211] \n",
      "0.6666 7.4239 12.6984 [-8605.61914601] \n",
      "0.8333 7.6018 6.9196 [-8604.77884432] \n",
      "0.9999 9.7689 1.3427 [-8599.85577546] \n"
     ]
    }
   ],
   "source": [
    "# VARY BETA: \n",
    "Nbeta = 4\n",
    "beta = np.linspace(0.5,0.9999,Nbeta)\n",
    "log_lik = np.nan + np.zeros((Nbeta,1))\n",
    "theta_hats =  np.nan + np.zeros((Nbeta,2))\n",
    "\n",
    "data = model.read_busdata(bustypes=[1,2,3,4])\n",
    "samplesize = data.shape[0]\n",
    "\n",
    "print(f'beta     RC     C       log_lik')\n",
    "for i in range(Nbeta):\n",
    "    \n",
    "    # Set up the model\n",
    "    do_settings = {\n",
    "    'beta': beta[i]\n",
    "    }\n",
    "    model = zurcher(**do_settings)\n",
    "\n",
    "\n",
    "    # Set-up solver\n",
    "    solver = solve_NFXP()\n",
    "\n",
    "    # Estimate the model\n",
    "    theta0 = [0,0]\n",
    "    nfxp_model, optim_res, pnames, theta_hat, Avar, converged=estimate.estimate(model, solver,data,theta0=theta0, twostep=0)\n",
    "\n",
    "    \n",
    "    theta_hats[i,0] = theta_hat[0]\n",
    "    theta_hats[i,1] = theta_hat[1]\n",
    "    log_lik[i]=-optim_res.fun*samplesize\n",
    "    print(f'{beta[i]:.4f} {theta_hats[i,0]:.4f} {theta_hats[i,1]:.4f} {log_lik[i]} ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. We use the latest EV guess to start the solve-procedure even though we change $\\theta$ from one likelihood iteration to another. Why do you think we do that? \n",
    "(a) What if we started over with EV=0 each iteration? Try that and see what happens with the parameters and the numerical performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same EV\n",
      "1.64 s Â± 292 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "EV=0\n",
      "1.97 s Â± 19.2 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "                 Same EV       EV=0\n",
      "RC               9.7689       9.7689\n",
      "c                1.3427       1.3427\n"
     ]
    }
   ],
   "source": [
    "import alternative_specifications_ex9 as a_s_ex9 \n",
    "\n",
    "# Ordinary\n",
    "print('Same EV')\n",
    "%timeit a_s_ex9.estimate(model, solver,data,0)\n",
    "nfxp_results_ord, theta_hat_ord = a_s_ex9.estimate(model, solver,data,0)\n",
    "\n",
    "\n",
    "# Change EV=0 in each iteration\n",
    "print('EV=0')\n",
    "%timeit a_s_ex9.estimate(model, solver,data,1)\n",
    "nfxp_results_diff, theta_hat_diff = a_s_ex9.estimate(model, solver,data,1)\n",
    "\n",
    "print('')\n",
    "print(f'                 Same EV       EV=0')\n",
    "print(f'{pnames[0]}               {theta_hat_ord[0]:.4f}       {theta_hat_diff[0]:.4f}')\n",
    "print(f'{pnames[1]}                {theta_hat_ord[1]:.4f}       {theta_hat_diff[1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Try setting the maximum number of miles (odometer reading) to 900. Now the absorbing state is much higher. \n",
    "\n",
    "(a) If we adjust the number of grid points as well, so that we have a comparable model (multiply the number of grids by 2), do we get a better fit? \n",
    "\n",
    "(b) Try to lower the number of grid points to 175 again. How do the parameters change? Are the changes intuitive? \n",
    "\n",
    "(c) What if you change the max to 225 and half the number of grids (hint: what goes wrong?)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for adjusting Grid-points\n",
    "def adjust_grid_point(maks, n):\n",
    "    # Set up the model\n",
    "    do_settings = {\n",
    "    'max': maks,\n",
    "    'n': n\n",
    "    }\n",
    "    model = zurcher(**do_settings)\n",
    "\n",
    "    # Set-up solver\n",
    "    solver = solve_NFXP()\n",
    "        \n",
    "    # Read the data\n",
    "    data = model.read_busdata(bustypes=[1,2,3,4])\n",
    "    samplesize = data.shape[0]\n",
    "\n",
    "    # Estimate the model\n",
    "    theta0 = [0,0]\n",
    "    breakpoint()\n",
    "    nfxp_model, result, pnames, theta, Avar, converged=estimate.estimate(model, solver,data,theta0=theta0, twostep=0)\n",
    "\n",
    "    \n",
    "    print(f'Parameters     Estimates    s.e. ') \n",
    "    print(f'{pnames[0]}             {theta[0]:.4f}     {np.sqrt(Avar[0,0]):.4f} ')\n",
    "    print(f'{pnames[1]}              {theta[1]:.4f}     {np.sqrt(Avar[1,1]):.4f} \\n ')\n",
    "    print(f'Log-likelihood now {-result.fun*samplesize:.4f}\\n \\n') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline\n",
      "Parameters     Estimates    s.e. \n",
      "RC             9.7689     1.2264 \n",
      "c              1.3427     0.3153 \n",
      " \n",
      "Log-likelihood now -8599.8558\n",
      " \n",
      "\n",
      "Question (a)\n",
      "Parameters     Estimates    s.e. \n",
      "RC             9.7656     1.2381 \n",
      "c              1.3402     0.3204 \n",
      " \n",
      "Log-likelihood now -8599.8737\n",
      " \n",
      "\n",
      "Question (b)\n",
      "Parameters     Estimates    s.e. \n",
      "RC             9.7455     1.2435 \n",
      "c              1.7876     0.4306 \n",
      " \n",
      "Log-likelihood now -7411.9098\n",
      " \n",
      "\n",
      "Question (c)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 87 is out of bounds for axis 0 with size 87",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# c) max =225, n = 175/2\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuestion (c)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[43madjust_grid_point\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m450\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m175\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m;\n",
      "Cell \u001b[0;32mIn[13], line 20\u001b[0m, in \u001b[0;36madjust_grid_point\u001b[0;34m(maks, n)\u001b[0m\n\u001b[1;32m     18\u001b[0m theta0 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mbreakpoint\u001b[39m()\n\u001b[0;32m---> 20\u001b[0m nfxp_model, result, pnames, theta, Avar, converged\u001b[38;5;241m=\u001b[39m\u001b[43mestimate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtheta0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtheta0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtwostep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParameters     Estimates    s.e. \u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpnames[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m             \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtheta[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m     \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39msqrt(Avar[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/github/DSE2025UCL/03_Schjerning_nfxp/code/exercises_python/ex_post/01_NFXP/estimate_NFXP.py:27\u001b[0m, in \u001b[0;36mestimate\u001b[0;34m(model, solver, data, theta0, twostep)\u001b[0m\n\u001b[1;32m     24\u001b[0m pnames \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRC\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Call BHHH optimizer\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mll\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtheta0\u001b[49m\u001b[43m,\u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpnames\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrust-ncg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mjac\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Update parameters\u001b[39;00m\n\u001b[1;32m     29\u001b[0m model \u001b[38;5;241m=\u001b[39m updatepar(model,pnames,res\u001b[38;5;241m.\u001b[39mx)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/scipy/optimize/_minimize.py:806\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    803\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_dogleg(fun, x0, args, jac, hess,\n\u001b[1;32m    804\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust-ncg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 806\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_trust_ncg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhessp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrust-krylov\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    809\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_trust_krylov(fun, x0, args, jac, hess, hessp,\n\u001b[1;32m    810\u001b[0m                                  callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/scipy/optimize/_trustregion_ncg.py:37\u001b[0m, in \u001b[0;36m_minimize_trust_ncg\u001b[0;34m(fun, x0, args, jac, hess, hessp, **trust_region_options)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hess \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m hessp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEither the Hessian or the Hessian-vector product \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     36\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis required for Newton-CG trust-region minimization\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_minimize_trust_region\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mhessp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhessp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubproblem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCGSteihaugSubproblem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrust_region_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/scipy/optimize/_trustregion.py:187\u001b[0m, in \u001b[0;36m_minimize_trust_region\u001b[0;34m(fun, x0, args, jac, hess, hessp, subproblem, initial_trust_radius, max_trust_radius, eta, gtol, maxiter, disp, return_all, callback, inexact, workers, **unknown_options)\u001b[0m\n\u001b[1;32m    179\u001b[0m x0 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x0)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# A ScalarFunction representing the problem. This caches calls to fun, jac,\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# hess.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# the workers kwd only has an effect for trust-ncg, trust-krylov when\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# estimating the Hessian with finite-differences. It's never used\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# during calculation of jacobian, because callables are required for all\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# methods.\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_scalar_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m fun \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mfun\n\u001b[1;32m    191\u001b[0m jac \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mgrad\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/scipy/optimize/_optimize.py:310\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess, workers)\u001b[0m\n\u001b[1;32m    306\u001b[0m workers \u001b[38;5;241m=\u001b[39m workers \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mmap\u001b[39m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43mScalarFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/scipy/optimize/_differentiable_functions.py:274\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon, workers)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# Initial function evaluation\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nfev \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;66;03m# Initial gradient evaluation\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped_grad \u001b[38;5;241m=\u001b[39m _ScalarGradWrapper(\n\u001b[1;32m    278\u001b[0m     grad,\n\u001b[1;32m    279\u001b[0m     fun\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped_fun,\n\u001b[1;32m    280\u001b[0m     args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m    281\u001b[0m     finite_diff_options\u001b[38;5;241m=\u001b[39mfinite_diff_options,\n\u001b[1;32m    282\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/scipy/optimize/_differentiable_functions.py:353\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 353\u001b[0m         fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    355\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m fx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_f:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/scipy/_lib/_util.py:590\u001b[0m, in \u001b[0;36m_ScalarFunctionWrapper.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;66;03m# The user of this class might want `x` to remain unchanged.\u001b[39;00m\n\u001b[0;32m--> 590\u001b[0m     fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n",
      "File \u001b[0;32m~/github/DSE2025UCL/03_Schjerning_nfxp/code/exercises_python/ex_post/01_NFXP/estimate_NFXP.py:74\u001b[0m, in \u001b[0;36mll\u001b[0;34m(theta, model, solver, data, pnames, out, no_guess)\u001b[0m\n\u001b[1;32m     71\u001b[0m ev, pk, dev \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39mpoly(model\u001b[38;5;241m.\u001b[39mbellman, V0\u001b[38;5;241m=\u001b[39mev0 ,beta\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mbeta, output\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Evaluate likelihood function\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m lik_pr \u001b[38;5;241m=\u001b[39m \u001b[43mpk\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# Get probability of keeping given observed state    \u001b[39;00m\n\u001b[1;32m     75\u001b[0m choice_prob \u001b[38;5;241m=\u001b[39m lik_pr \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m d) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mlik_pr) \u001b[38;5;241m*\u001b[39m d \u001b[38;5;66;03m# get probability of making observed choice\u001b[39;00m\n\u001b[1;32m     76\u001b[0m log_lik \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(choice_prob)  \u001b[38;5;66;03m# Compute log-likelihood-contributions\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 87 is out of bounds for axis 0 with size 87"
     ]
    }
   ],
   "source": [
    "# Baseline max = 450, n = 175\n",
    "print(f'Baseline')\n",
    "adjust_grid_point(450,175);\n",
    "\n",
    "# a)  max = 900, n = 175*2\n",
    "print(f'Question (a)')\n",
    "adjust_grid_point(450*2,175*2)\n",
    "\n",
    "# b) max = 600, n = 175\n",
    "print(f'Question (b)')\n",
    "adjust_grid_point(600,175)\n",
    "\n",
    "# c) max =225, n = 175/2\n",
    "print(f'Question (c)')\n",
    "adjust_grid_point(int(450/2),int(175/2));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
